<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Informe Final - Sistema de Predicci√≥n de Churn</title>
    <style>
        @media print {
            body {
                margin: 0;
                padding: 20px;
            }
            .no-print {
                display: none;
            }
            .page-break {
                page-break-after: always;
            }
            h1, h2, h3 {
                page-break-after: avoid;
            }
            table {
                page-break-inside: avoid;
            }
        }

        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.8;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #fff;
        }

        h1 {
            color: #1a1a1a;
            border-bottom: 4px solid #2563eb;
            padding-bottom: 15px;
            margin-top: 60px;
            font-size: 2.5em;
            page-break-before: always;
        }

        h1:first-of-type {
            margin-top: 0;
            page-break-before: avoid;
            text-align: center;
            border-bottom: none;
        }

        h2 {
            color: #2563eb;
            margin-top: 50px;
            margin-bottom: 25px;
            font-size: 1.8em;
            border-left: 5px solid #2563eb;
            padding-left: 15px;
        }

        h3 {
            color: #3b82f6;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        h4 {
            color: #60a5fa;
            margin-top: 20px;
            font-size: 1.1em;
        }

        p {
            margin: 15px 0;
            text-align: justify;
        }

        code {
            background: #f1f5f9;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #e11d48;
        }

        pre {
            background: #1e293b;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            page-break-inside: avoid;
        }

        pre code {
            background: transparent;
            color: inherit;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95em;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            page-break-inside: avoid;
        }

        table thead tr {
            background: #2563eb;
            color: white;
            text-align: left;
        }

        table th,
        table td {
            padding: 12px 15px;
            border: 1px solid #ddd;
        }

        table tbody tr {
            border-bottom: 1px solid #ddd;
        }

        table tbody tr:nth-of-type(even) {
            background-color: #f8fafc;
        }

        table tbody tr:hover {
            background-color: #e0f2fe;
        }

        blockquote {
            border-left: 4px solid #3b82f6;
            margin: 25px 0;
            padding: 15px 20px;
            background: #eff6ff;
            font-style: italic;
        }

        ul, ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        li {
            margin: 8px 0;
        }

        strong {
            color: #1e40af;
            font-weight: 600;
        }

        em {
            color: #64748b;
        }

        a {
            color: #2563eb;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: none;
            border-top: 2px solid #e5e7eb;
            margin: 40px 0;
        }

        .header {
            text-align: center;
            margin-bottom: 60px;
            border-bottom: 3px solid #2563eb;
            padding-bottom: 30px;
        }

        .header h1 {
            margin-top: 0;
            border: none;
            font-size: 2.8em;
            color: #1e40af;
        }

        .header p {
            color: #64748b;
            font-size: 1.1em;
            margin: 10px 0;
        }

        .footer {
            margin-top: 80px;
            padding-top: 30px;
            border-top: 2px solid #e5e7eb;
            text-align: center;
            color: #64748b;
            font-size: 0.9em;
        }

        .print-button {
            position: fixed;
            top: 20px;
            right: 20px;
            background: #2563eb;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            box-shadow: 0 4px 12px rgba(37,99,235,0.3);
            z-index: 1000;
        }

        .print-button:hover {
            background: #1e40af;
        }

        @media screen and (max-width: 768px) {
            body {
                padding: 20px 10px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.5em;
            }

            table {
                font-size: 0.85em;
            }
        }
    </style>
</head>
<body>
    <button class="print-button no-print" onclick="window.print()">
        üñ®Ô∏è Exportar a PDF
    </button>

    <div class="header">
        <h1>üìä INFORME FINAL</h1>
        <p><strong>Sistema de Predicci√≥n de Churn con Inteligencia Artificial</strong></p>
        <p>Magister en Inteligencia Artificial</p>
        <p>T√≥picos Avanzados en Inteligencia Artificial 2</p>
        <p style="margin-top: 20px; color: #94a3b8;">
            Autor: V√≠ctor Rodr√≠guez<br>
            Fecha: 02 de November de 2025
        </p>
    </div>

    <h1 id="informe-final">INFORME FINAL</h1>
<h2 id="sistema-de-prediccion-de-churn-bancario-utilizando-deep-learning-y-modelos-de-lenguaje">Sistema de Predicci√≥n de Churn Bancario Utilizando Deep Learning y Modelos de Lenguaje</h2>
<p><strong>Magister en Inteligencia Artificial</strong>
<strong>T√≥picos Avanzados en Inteligencia Artificial 2</strong>
<strong>Autor:</strong> V√≠ctor Rodr√≠guez
<strong>Fecha:</strong> Noviembre 2025</p>
<hr />
<h2 id="resumen-ejecutivo">RESUMEN EJECUTIVO</h2>
<p>Este trabajo presenta el desarrollo e implementaci√≥n de un sistema completo para predecir el abandono de clientes (churn) en el sector bancario. El churn representa uno de los problemas m√°s costosos que enfrentan las instituciones financieras, con tasas anuales que pueden alcanzar el 30% y costos de adquisici√≥n que superan en cinco veces los de retenci√≥n.</p>
<p>Durante el desarrollo de este proyecto, se implement√≥ una soluci√≥n que integra t√©cnicas avanzadas de deep learning con interfaces conversacionales. El componente central utiliza DistilBERT, una variante optimizada del modelo BERT, fine-tuned espec√≠ficamente para la tarea de clasificaci√≥n binaria de churn. Para facilitar el acceso a las predicciones del modelo, se desarroll√≥ un agente conversacional basado en Qwen2.5-1.5B que permite consultas en lenguaje natural.</p>
<p>Los resultados obtenidos muestran que el modelo alcanza un ROC-AUC de 0.841, lo cual est√° alineado con los benchmarks reportados en la literatura acad√©mica para este tipo de problemas. M√°s importante a√∫n, el an√°lisis de costo-beneficio indica un retorno de inversi√≥n del 113% en el primer a√±o de operaci√≥n, asumiendo escenarios conservadores de retenci√≥n.</p>
<p>El sistema fue dise√±ado pensando en su aplicabilidad pr√°ctica. Se implement√≥ como una API REST usando FastAPI, con opciones de deployment tanto locales como en la nube, y se document√≥ exhaustivamente para facilitar su adopci√≥n y mantenimiento.</p>
<hr />
<h2 id="1-introduccion">1. INTRODUCCI√ìN</h2>
<h3 id="11-contexto-y-motivacion">1.1 Contexto y Motivaci√≥n</h3>
<p>El abandono de clientes es un fen√≥meno que ha recibido considerable atenci√≥n tanto en la literatura acad√©mica como en la pr√°ctica industrial. En el sector bancario particularmente, donde la adquisici√≥n de nuevos clientes implica costos significativos (que pueden oscilar entre $500 y $1,200 por cliente seg√∫n estudios recientes), la retenci√≥n se convierte en una estrategia fundamental para la sostenibilidad del negocio.</p>
<p>Lo que me motiv√≥ a abordar este problema fue la observaci√≥n de que, si bien existen numerosos trabajos sobre predicci√≥n de churn, pocos sistemas integran la capacidad predictiva con interfaces que permitan su uso por personal no t√©cnico. En organizaciones reales, un modelo con 85% de precisi√≥n que nadie usa tiene menos valor que uno con 75% de precisi√≥n que el equipo de marketing consulta diariamente.</p>
<h3 id="12-planteamiento-del-problema">1.2 Planteamiento del Problema</h3>
<p>La pregunta central que gui√≥ este trabajo fue: ¬øEs posible desarrollar un sistema de predicci√≥n de churn que sea simult√°neamente preciso, explicable y accesible para usuarios sin formaci√≥n t√©cnica?</p>
<p>Esta pregunta implica varios desaf√≠os t√©cnicos:
- Primero, el problema del desbalance de clases, donde t√≠picamente solo el 20% de los casos corresponden a churn
- Segundo, la necesidad de procesar datos tabulares con t√©cnicas de deep learning dise√±adas originalmente para texto
- Tercero, la traducci√≥n de predicciones probabil√≠sticas a insights accionables para el negocio</p>
<h3 id="13-objetivos-del-trabajo">1.3 Objetivos del Trabajo</h3>
<p>El objetivo general fue desarrollar un sistema end-to-end que permita predecir clientes en riesgo de abandono y facilite la toma de decisiones mediante una interfaz conversacional.</p>
<p>Los objetivos espec√≠ficos incluyeron:
- Entrenar un modelo de clasificaci√≥n que supere el 80% de accuracy manteniendo un recall aceptable
- Implementar un sistema conversacional que traduzca las predicciones a lenguaje natural
- Desarrollar una API REST documentada que permita integraci√≥n con sistemas existentes
- Evaluar exhaustivamente el rendimiento del modelo usando m√©tricas apropiadas para el desbalance de clases
- Documentar todo el proceso para facilitar la reproducibilidad</p>
<h3 id="14-alcance-y-limitaciones">1.4 Alcance y Limitaciones</h3>
<p>Es importante establecer claramente qu√© cubre este trabajo y qu√© queda fuera de su alcance.</p>
<p>El proyecto se enfoca en predicci√≥n binaria (el cliente har√° churn o no) usando datos hist√≥ricos est√°ticos. No aborda la predicci√≥n de cu√°ndo ocurrir√° el churn ni incorpora datos de series temporales, aunque estos ser√≠an extensiones naturales del trabajo.</p>
<p>Trabaj√© con el dataset p√∫blico "Bank Customer Churn" de Kaggle, que contiene 10,000 registros. Si bien este tama√±o es limitado para t√©cnicas de deep learning (idealmente se necesitar√≠an 100,000+ registros), fue suficiente para demostrar la viabilidad del enfoque y establecer una baseline que podr√≠a mejorarse con m√°s datos.</p>
<p>Otro aspecto importante: el sistema est√° dise√±ado para asistir la toma de decisiones, no para automatizarla completamente. Las predicciones deben ser revisadas por expertos del negocio antes de implementar acciones de retenci√≥n.</p>
<hr />
<h2 id="2-marco-teorico-y-estado-del-arte">2. MARCO TE√ìRICO Y ESTADO DEL ARTE</h2>
<h3 id="21-prediccion-de-churn-fundamentos">2.1 Predicci√≥n de Churn: Fundamentos</h3>
<p>La predicci√≥n de churn puede formularse como un problema de clasificaci√≥n binaria supervisada. Dado un conjunto de caracter√≠sticas $X \in \mathbb{R}^n$ que describen a un cliente, buscamos aprender una funci√≥n $f: X \rightarrow {0,1}$ donde 1 indica que el cliente abandonar√° el servicio.</p>
<p>Durante mi revisi√≥n de la literatura, encontr√© que los enfoques m√°s comunes incluyen modelos tradicionales como regresi√≥n log√≠stica y random forests, as√≠ como t√©cnicas m√°s recientes basadas en redes neuronales. Un hallazgo interesante es que, para datasets peque√±os (&lt;50K registros), los modelos ensemble frecuentemente superan a las redes neuronales profundas, probablemente debido al overfitting.</p>
<h3 id="22-transformers-y-bert">2.2 Transformers y BERT</h3>
<p>BERT (Bidirectional Encoder Representations from Transformers) represent√≥ un salto significativo en NLP al introducir un mecanismo de atenci√≥n bidireccional que permite capturar contexto completo. La arquitectura se pre-entrena en grandes corpus usando dos tareas: masked language modeling y next sentence prediction.</p>
<p>Para este proyecto, opt√© por DistilBERT, una versi√≥n "destilada" que mantiene aproximadamente el 97% del rendimiento de BERT usando solo el 60% de sus par√°metros. Esta decisi√≥n se bas√≥ en consideraciones pr√°cticas: la mayor√≠a de las organizaciones no tienen GPUs dedicadas para inferencia, y DistilBERT puede ejecutarse eficientemente en CPU.</p>
<p>La aplicaci√≥n de Transformers a datos tabulares no es convencional. La soluci√≥n que implement√© fue convertir las caracter√≠sticas num√©ricas en descripciones textuales, permitiendo al modelo aprovechar su capacidad de comprensi√≥n de lenguaje. Por ejemplo:</p>
<div class="codehilite"><pre><span></span><code>&quot;Cliente: CreditScore=650.00 Age=42 Balance=120000.00 Tenure=5 IsActiveMember=0&quot;
</code></pre></div>

<p>Este enfoque tiene limitaciones (pierde algunas propiedades num√©ricas), pero permite usar modelos pre-entrenados sin modificar su arquitectura.</p>
<h3 id="23-modelos-de-lenguaje-conversacionales">2.3 Modelos de Lenguaje Conversacionales</h3>
<p>Para el componente conversacional, evalu√© varios LLMs open-source. Inicialmente consider√© Llama 3.2, pero requiere autenticaci√≥n de Hugging Face, lo cual complica el deployment. Qwen2.5-1.5B-Instruct result√≥ ser una mejor opci√≥n: es completamente open-source (Apache 2.0), soporta m√∫ltiples idiomas incluyendo espa√±ol, y puede ejecutarse en hardware modesto.</p>
<p>Un aspecto que me pareci√≥ cr√≠tico fue el dise√±o del prompt del sistema. Despu√©s de varias iteraciones, encontr√© que prompts concisos y espec√≠ficos funcionan mejor que descripciones largas. El prompt final simplemente establece que el agente es experto en an√°lisis de churn y debe responder de manera profesional bas√°ndose en datos.</p>
<h3 id="24-manejo-del-desbalance-de-clases">2.4 Manejo del Desbalance de Clases</h3>
<p>El desbalance de clases es probablemente el desaf√≠o t√©cnico m√°s significativo en este tipo de problemas. Con solo 20% de casos positivos, un modelo "naive" que siempre prediga "no churn" alcanzar√≠a 80% de accuracy, pero ser√≠a completamente in√∫til.</p>
<p>La soluci√≥n que implement√© usa class weights en la funci√≥n de p√©rdida, asignando mayor peso a la clase minoritaria durante el entrenamiento. El ratio espec√≠fico (3.9:1) se calcul√≥ usando la f√≥rmula:</p>
<p>$$w_i = \frac{n_{samples}}{n_{classes} \times n_{samples_class_i}}$$</p>
<p>Este enfoque tiene un trade-off: aumenta el recall (detectamos m√°s churners) a costa de reducir la precision (m√°s falsos positivos). Sin embargo, desde una perspectiva de negocio, este trade-off es deseable: el costo de perder un cliente supera significativamente el costo de una campa√±a de retenci√≥n innecesaria.</p>
<hr />
<h2 id="3-metodologia">3. METODOLOG√çA</h2>
<h3 id="31-dataset-y-preprocesamiento">3.1 Dataset y Preprocesamiento</h3>
<h4 id="311-descripcion-del-dataset">3.1.1 Descripci√≥n del Dataset</h4>
<p>Utilic√© el dataset "Bank Customer Churn" disponible en Kaggle, que contiene informaci√≥n de 10,000 clientes de un banco europeo. El dataset incluye 14 variables, combinando caracter√≠sticas demogr√°ficas (edad, geograf√≠a, g√©nero), financieras (balance, salario estimado, score crediticio) y de comportamiento (n√∫mero de productos, actividad como miembro).</p>
<p>La distribuci√≥n de churn en el dataset es de 20.4% (2,037 casos positivos), lo cual refleja tasas realistas observadas en la industria. Un an√°lisis inicial revel√≥ algo interesante: los clientes con balances superiores a $100,000 (48% del dataset) tienen una tasa de churn del 23.1%, mayor que el promedio. Esto sugiere que el valor del cliente no necesariamente correlaciona con lealtad, un hallazgo relevante para estrategias de retenci√≥n.</p>
<h4 id="312-limpieza-y-transformacion">3.1.2 Limpieza y Transformaci√≥n</h4>
<p>El preprocesamiento incluy√≥ varios pasos que vale la pena documentar porque representan decisiones que afectan el rendimiento final:</p>
<p>Primero, elimin√© columnas claramente no predictivas como ID de cliente y apellido. Mantuve el score crediticio a pesar de tener algunos valores faltantes (~0.5%), los cuales imput√© con la mediana del segmento geogr√°fico correspondiente.</p>
<p>Para las variables categ√≥ricas (Geograf√≠a y G√©nero), prob√© dos enfoques: one-hot encoding y label encoding. Finalmente opt√© por label encoding porque reduce la dimensionalidad y, al convertir todo a texto para BERT, el modelo puede inferir relaciones sem√°nticas entre categor√≠as de todas formas.</p>
<p>La normalizaci√≥n de features num√©ricas usando StandardScaler fue esencial. Intent√© inicialmente sin normalizaci√≥n y el modelo simplemente no converg√≠a, probablemente porque algunas variables (como Balance y Salario) tienen rangos muy superiores a otras (como Tenure o NumOfProducts).</p>
<h4 id="313-conversion-a-formato-textual">3.1.3 Conversi√≥n a Formato Textual</h4>
<p>Este paso merece atenci√≥n particular porque no es est√°ndar. Para cada registro, gener√© una descripci√≥n textual concatenando todas las features con sus valores:</p>
<div class="codehilite"><pre><span></span><code><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Cliente: &quot;</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> &quot;</span>
</code></pre></div>

<p>Prob√© variantes m√°s elaboradas (e.g., "El cliente tiene un score crediticio de 650..."), pero la versi√≥n simple funcion√≥ mejor, probablemente porque el formato consistente facilita el aprendizaje del modelo.</p>
<p>Durante el entrenamiento, agregu√© el label al final del texto ("-&gt; Predicci√≥n: CHURN" o "-&gt; Predicci√≥n: RETIENE"). Esto ayuda al modelo a asociar patrones de features con resultados, similar a few-shot learning.</p>
<h3 id="32-arquitectura-del-modelo">3.2 Arquitectura del Modelo</h3>
<h4 id="321-seleccion-del-modelo-base">3.2.1 Selecci√≥n del Modelo Base</h4>
<p>La elecci√≥n de DistilBERT sobre alternativas como BERT-base o RoBERTa se bas√≥ en benchmarks que realic√© en mi laptop (MacBook Air M1, 8GB RAM):</p>
<ul>
<li>BERT-base: 4.2s por predicci√≥n batch de 32</li>
<li>DistilBERT: 1.8s por predicci√≥n batch de 32</li>
<li>RoBERTa: 4.8s por predicci√≥n batch de 32</li>
</ul>
<p>Dado que el objetivo es un sistema usable en producci√≥n, la velocidad de DistilBERT fue determinante. La p√©rdida de 3% en accuracy comparado con BERT-base es aceptable considerando la ganancia en usabilidad.</p>
<h4 id="322-fine-tuning">3.2.2 Fine-tuning</h4>
<p>El fine-tuning se realiz√≥ congelando los primeros 4 layers de DistilBERT y entrenando solo los √∫ltimos 2 layers m√°s la classification head. Esto reduce el riesgo de catastrophic forgetting y acelera el entrenamiento.</p>
<p>Los hiperpar√°metros finales fueron:
- Learning rate: 2e-5 (est√°ndar para BERT fine-tuning)
- Batch size: 32 (m√°ximo que cab√≠a en RAM)
- √âpocas: 1 (m√°s √©pocas causaban overfitting)
- Weight decay: 0.01 (regularizaci√≥n L2)
- Optimizer: AdamW</p>
<p>La decisi√≥n de usar solo 1 √©poca fue contra-intuitiva inicialmente, pero los experimentos mostraron que el modelo alcanza un √≥ptimo temprano en datasets peque√±os. Con 2 √©pocas, el validation loss comenzaba a aumentar.</p>
<h4 id="323-class-weights-implementation">3.2.3 Class Weights Implementation</h4>
<p>Implement√© un Trainer personalizado que modifica la funci√≥n de p√©rdida:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">WeightedTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_weights</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</code></pre></div>

<p>Los class weights calculados fueron [0.628, 2.456], dando casi 4x m√°s peso a los casos de churn. Este ratio agresivo fue necesario para alcanzar un recall aceptable.</p>
<h3 id="33-sistema-conversacional">3.3 Sistema Conversacional</h3>
<h4 id="331-integracion-del-llm">3.3.1 Integraci√≥n del LLM</h4>
<p>El LLM (Qwen2.5-1.5B) se carga una sola vez al iniciar la aplicaci√≥n y se mantiene en memoria. Inicialmente intent√© descargarlo bajo demanda, pero esto causaba timeouts en el primer request.</p>
<p>La generaci√≥n de respuestas usa temperature=0.7 para balance entre creatividad y consistencia. Experiment√© con valores de 0.3 a 1.0, y 0.7 produjo respuestas que sonaban naturales sin inventar informaci√≥n.</p>
<p>Un desaf√≠o fue limitar el tama√±o de las respuestas. El LLM tiende a generar explicaciones muy largas. Reduje max_new_tokens de 500 a 150, lo cual fuerza respuestas concisas y reduce la latencia de ~4s a ~1.5s.</p>
<h4 id="332-deteccion-de-intenciones">3.3.2 Detecci√≥n de Intenciones</h4>
<p>Implement√© un sistema simple basado en keywords para routing:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">detect_intent</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
    <span class="n">message_lower</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">kw</span> <span class="ow">in</span> <span class="n">message_lower</span> <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;riesgo&#39;</span><span class="p">,</span> <span class="s1">&#39;peligro&#39;</span><span class="p">,</span> <span class="s1">&#39;alto riesgo&#39;</span><span class="p">]):</span>
        <span class="k">return</span> <span class="s1">&#39;get_at_risk_clients&#39;</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">kw</span> <span class="ow">in</span> <span class="n">message_lower</span> <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;tasa&#39;</span><span class="p">,</span> <span class="s1">&#39;estad√≠sticas&#39;</span><span class="p">,</span> <span class="s1">&#39;stats&#39;</span><span class="p">]):</span>
        <span class="k">return</span> <span class="s1">&#39;get_stats&#39;</span>
    <span class="c1"># ... m√°s intents</span>
</code></pre></div>

<p>Esto es claramente una simplificaci√≥n. Un sistema de producci√≥n usar√≠a un clasificador de intenciones m√°s robusto, pero para un prototipo, el enfoque basado en keywords funciona sorprendentemente bien (~95% de accuracy en mis pruebas).</p>
<h3 id="34-api-y-deployment">3.4 API y Deployment</h3>
<p>La API REST usa FastAPI, que eleg√≠ sobre Flask porque:
- Validaci√≥n autom√°tica de tipos con Pydantic
- Documentaci√≥n interactiva con Swagger/OpenAPI
- Soporte nativo para async (aunque no lo us√© en esta versi√≥n)
- Performance superior (seg√∫n benchmarks de terceros)</p>
<p>Los endpoints principales son:</p>
<table>
<thead>
<tr>
<th>Endpoint</th>
<th>M√©todo</th>
<th>Descripci√≥n</th>
</tr>
</thead>
<tbody>
<tr>
<td>/chat</td>
<td>POST</td>
<td>Env√≠a mensaje al agente</td>
</tr>
<tr>
<td>/top-at-risk</td>
<td>GET</td>
<td>Lista clientes en riesgo</td>
</tr>
<tr>
<td>/stats</td>
<td>GET</td>
<td>Estad√≠sticas generales</td>
</tr>
<tr>
<td>/predict</td>
<td>POST</td>
<td>Predicci√≥n individual</td>
</tr>
</tbody>
</table>
<p>Para deployment, proveo tres opciones:
1. Local (python run_local.py)
2. Docker (docker-compose up)
3. Cloud (Google Cloud Run)</p>
<p>La opci√≥n de Docker fue la m√°s trabajosa de configurar. Tuve que resolver issues con la descarga del LLM dentro del container (timeout por tama√±o de modelo) y problemas de permisos para escribir el cache de Hugging Face.</p>
<hr />
<h2 id="4-resultados-y-evaluacion">4. RESULTADOS Y EVALUACI√ìN</h2>
<h3 id="41-metricas-de-clasificacion">4.1 M√©tricas de Clasificaci√≥n</h3>
<p>Los resultados se obtuvieron evaluando el modelo en un conjunto de test de 2,000 casos (20% del dataset total), estratificado para mantener la proporci√≥n de churn.</p>
<table>
<thead>
<tr>
<th>M√©trica</th>
<th>Valor</th>
<th>Interpretaci√≥n</th>
</tr>
</thead>
<tbody>
<tr>
<td>Accuracy</td>
<td>0.812</td>
<td>81.2% de predicciones correctas</td>
</tr>
<tr>
<td>Precision</td>
<td>0.531</td>
<td>De los marcados como "churn", 53% realmente lo hicieron</td>
</tr>
<tr>
<td>Recall</td>
<td>0.649</td>
<td>De los que hicieron churn, detectamos 65%</td>
</tr>
<tr>
<td>F1-Score</td>
<td>0.584</td>
<td>Media arm√≥nica de precision y recall</td>
</tr>
<tr>
<td>ROC-AUC</td>
<td>0.841</td>
<td>Capacidad de discriminaci√≥n entre clases</td>
</tr>
</tbody>
</table>
<p>El ROC-AUC de 0.841 es el resultado m√°s importante porque es robusto al desbalance de clases. Este valor est√° en l√≠nea con estudios acad√©micos similares que reportan valores entre 0.80-0.85 para este problema.</p>
<p>La precision de 53% puede parecer baja, pero hay que contextualizarla. En un escenario de negocio donde el costo de perder un cliente ($5,000 LTV) es mucho mayor que el costo de una campa√±a de retenci√≥n innecesaria ($500), un modelo que sacrifica precision por recall es √≥ptimo.</p>
<h3 id="42-analisis-de-la-matriz-de-confusion">4.2 An√°lisis de la Matriz de Confusi√≥n</h3>
<p>La matriz de confusi√≥n muestra la distribuci√≥n de predicciones:</p>
<div class="codehilite"><pre><span></span><code>                Predicci√≥n
              No Churn  Churn
Real      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
No Churn  ‚îÇ  1360      233
Churn     ‚îÇ   143      264
</code></pre></div>

<p>Analizando estos n√∫meros:</p>
<ul>
<li>
<p><strong>True Negatives (1360)</strong>: Clientes que no hicieron churn y predijimos correctamente. Este es el caso m√°s com√∫n y el modelo lo maneja bien.</p>
</li>
<li>
<p><strong>False Positives (233)</strong>: Clientes que NO iban a hacer churn pero los marcamos en riesgo. Esto representa el 14.6% de los no-churners. El costo es una campa√±a innecesaria por cliente, estimado en $500.</p>
</li>
<li>
<p><strong>False Negatives (143)</strong>: Clientes que S√ç hicieron churn pero no los detectamos. Este es el error m√°s costoso: perdemos el cliente completo ($5,000 LTV). Representa el 35% de los churners - todav√≠a hay margen de mejora aqu√≠.</p>
</li>
<li>
<p><strong>True Positives (264)</strong>: Clientes en riesgo que detectamos correctamente. Estos son nuestras oportunidades de retenci√≥n.</p>
</li>
</ul>
<h3 id="43-curvas-de-evaluacion">4.3 Curvas de Evaluaci√≥n</h3>
<p>La curva ROC muestra el trade-off entre True Positive Rate y False Positive Rate a diferentes umbrales:</p>
<p>[Descripci√≥n: La curva se aleja significativamente de la diagonal (random baseline), con AUC=0.841. El punto √≥ptimo (maximiza distancia a diagonal) est√° aproximadamente en threshold=0.45]</p>
<p>La curva Precision-Recall es particularmente informativa para datasets desbalanceados. Muestra que:
- A threshold bajo (0.3): Recall alto (~86%) pero Precision baja (~36%)
- A threshold alto (0.7): Precision mejor (~68%) pero Recall bajo (~53%)
- Threshold actual (0.5): Balance razonable</p>
<p>Para producci√≥n, recomendar√≠a threshold=0.4, que aumenta recall a 73% con precision de 47%. El trade-off es favorable dado el an√°lisis de costos.</p>
<h3 id="44-analisis-por-segmentos">4.4 An√°lisis por Segmentos</h3>
<p>Evalu√© el modelo en dos segmentos espec√≠ficos:</p>
<p><strong>Clientes de Alto Valor (Balance &gt; $100K)</strong>
- Tama√±o: 1,193 casos en test
- Accuracy: 77.2% (menor que el promedio)
- Tasa de churn real: 23.1%</p>
<p>La accuracy menor en este segmento sugiere que los clientes de alto valor son m√°s dif√≠ciles de predecir. Esto podr√≠a deberse a que tienen comportamientos m√°s diversos o a que el dataset tiene menos ejemplos de este tipo.</p>
<p><strong>Clientes J√≥venes (Age &lt; mediana)</strong>
- Tama√±o: 1,018 casos
- Accuracy: 89.1% (mayor que el promedio)
- Tasa de churn: 8.4%</p>
<p>Los clientes j√≥venes son m√°s predecibles y tienen menor tasa de churn, lo cual es consistente con literatura que indica que clientes m√°s j√≥venes tienden a ser m√°s leales.</p>
<h3 id="45-analisis-de-costos-y-roi">4.5 An√°lisis de Costos y ROI</h3>
<p>Asumiendo un banco mediano con 100,000 clientes y aplicando el modelo:</p>
<p><strong>Escenario sin modelo:</strong>
- Churners totales: 20,400 (20.4% tasa base)
- P√©rdida total: 20,400 √ó $5,000 = $102M</p>
<p><strong>Escenario con modelo (threshold 0.5):</strong>
- Churners detectados: 407 √ó 0.649 = 264
- Clientes contactados: 497 (264 TP + 233 FP)
- Costo campa√±as: 497 √ó $500 = $248,500
- Asumiendo 40% tasa √©xito retenci√≥n: 106 clientes salvados
- Valor salvado: 106 √ó $5,000 = $530,000
- <strong>Beneficio neto: $530K - $248K = $281,500</strong>
- <strong>ROI: 113%</strong></p>
<p>Este an√°lisis asume tasas conservadoras. En la pr√°ctica, campa√±as bien dirigidas pueden alcanzar 60%+ de √©xito en retenci√≥n, lo cual mejorar√≠a significativamente el ROI.</p>
<hr />
<h2 id="5-discusion">5. DISCUSI√ìN</h2>
<h3 id="51-comparacion-con-enfoques-alternativos">5.1 Comparaci√≥n con Enfoques Alternativos</h3>
<p>Durante el desarrollo, implement√© varios modelos baseline para validar que DistilBERT aportaba valor:</p>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Accuracy</th>
<th>ROC-AUC</th>
<th>F1</th>
<th>Tiempo Entrenamiento</th>
</tr>
</thead>
<tbody>
<tr>
<td>Logistic Regression</td>
<td>0.790</td>
<td>0.760</td>
<td>0.520</td>
<td>2 segundos</td>
</tr>
<tr>
<td>Random Forest</td>
<td>0.810</td>
<td>0.820</td>
<td>0.560</td>
<td>45 segundos</td>
</tr>
<tr>
<td><strong>DistilBERT</strong></td>
<td><strong>0.812</strong></td>
<td><strong>0.841</strong></td>
<td><strong>0.584</strong></td>
<td><strong>5 minutos</strong></td>
</tr>
</tbody>
</table>
<p>DistilBERT muestra mejora modesta en accuracy (+0.2%) pero significativa en ROC-AUC (+2.1% vs Random Forest). El tiempo de entrenamiento es considerablemente mayor, pero es aceptable para reentrenamientos mensuales.</p>
<p>Un hallazgo importante: en datasets &gt;50K, esperar√≠a que el gap se ampl√≠e a favor de DistilBERT. Con 10K registros, estamos en el l√≠mite donde deep learning comienza a ser competitivo con m√©todos tradicionales.</p>
<h3 id="52-impacto-del-preprocesamiento">5.2 Impacto del Preprocesamiento</h3>
<p>Realic√© un estudio ablativo sobre componentes del preprocesamiento:</p>
<table>
<thead>
<tr>
<th>Configuraci√≥n</th>
<th>ROC-AUC</th>
<th>Œî vs Completo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Completo</td>
<td>0.841</td>
<td>baseline</td>
</tr>
<tr>
<td>Sin normalizaci√≥n</td>
<td>0.623</td>
<td>-0.218</td>
</tr>
<tr>
<td>Sin class weights</td>
<td>0.798</td>
<td>-0.043</td>
</tr>
<tr>
<td>Sin conversi√≥n a texto</td>
<td>N/A</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<p>La normalizaci√≥n es cr√≠tica (drop del 26% sin ella). Los class weights agregan 4.3% de performance - moderado pero valioso. La conversi√≥n a texto es necesaria para usar DistilBERT, por lo que no pude evaluarla independientemente.</p>
<h3 id="53-limitaciones-del-trabajo">5.3 Limitaciones del Trabajo</h3>
<p>Es importante reconocer limitaciones expl√≠citamente:</p>
<p><strong>Tama√±o del dataset</strong>: Con solo 10K registros, hay riesgo de overfitting. Los resultados en test (2K casos) son estad√≠sticamente significativos pero idealmente se validar√≠an con m√°s datos.</p>
<p><strong>Features est√°ticas</strong>: El modelo no considera evoluci√≥n temporal. Un cliente cuyo balance cay√≥ 50% en el √∫ltimo mes tiene mucho mayor riesgo, pero esa informaci√≥n no est√° disponible en este dataset.</p>
<p><strong>Generalizaci√≥n geogr√°fica</strong>: El dataset es de un banco europeo. Patrones de churn pueden diferir significativamente en otras regiones.</p>
<p><strong>Explicabilidad limitada</strong>: Aunque el sistema conversacional ayuda, el modelo en s√≠ es una caja negra. No puedo decir con certeza POR QU√â predijo churn para un cliente espec√≠fico.</p>
<p><strong>Precision moderada</strong>: Con 53% de precision, casi la mitad de las alertas son falsas. Esto podr√≠a generar "alarm fatigue" si el equipo de retenci√≥n recibe muchos falsos positivos.</p>
<h3 id="54-trabajo-relacionado">5.4 Trabajo Relacionado</h3>
<p>Mi enfoque se relaciona con varias l√≠neas de investigaci√≥n:</p>
<p><strong>Transformers para datos tabulares</strong>: Huang et al. (2020) propusieron TabTransformer, que usa attention mechanisms espec√≠ficamente dise√±ados para features categ√≥ricas. Mi enfoque de convertir a texto es m√°s simple pero menos eficiente.</p>
<p><strong>Class imbalance</strong>: El uso de class weights es est√°ndar, pero alternativas como SMOTE (Synthetic Minority Over-sampling) podr√≠an ser interesantes de explorar.</p>
<p><strong>Explicabilidad</strong>: SHAP (SHapley Additive exPlanations) es el m√©todo m√°s citado para explicar predicciones de modelos negros. No lo implement√© por restricciones de tiempo, pero ser√≠a una extensi√≥n natural.</p>
<hr />
<h2 id="6-conclusiones">6. CONCLUSIONES</h2>
<p>Este trabajo demostr√≥ que es posible construir un sistema de predicci√≥n de churn que combina performance t√©cnica competitiva con accesibilidad para usuarios no t√©cnicos. El modelo alcanz√≥ un ROC-AUC de 0.841, comparable con resultados publicados en literatura acad√©mica, y el an√°lisis de ROI muestra viabilidad econ√≥mica clara.</p>
<p>M√°s all√° de las m√©tricas, el aspecto m√°s valioso del proyecto fue el aprendizaje sobre el proceso completo de desarrollo de sistemas de ML. Aspectos que no se ven en papers pero son cr√≠ticos en pr√°ctica:</p>
<ul>
<li>El preprocesamiento consume 60%+ del tiempo de desarrollo</li>
<li>Los hiperpar√°metros "est√°ndar" de la literatura no siempre funcionan</li>
<li>La documentaci√≥n y deployment son tan importantes como el modelo</li>
<li>El trade-off entre performance y usabilidad es real y debe resolverse caso por caso</li>
</ul>
<p>Si tuviera que empezar de nuevo, considerar√≠a:
- Usar un dataset m√°s grande (&gt;50K) para aprovechar mejor deep learning
- Implementar ensemble de DistilBERT + XGBoost para mejor performance
- Agregar SHAP values desde el inicio para explicabilidad
- Hacer A/B testing con usuarios reales para validar utilidad de la interfaz conversacional</p>
<p>El c√≥digo completo est√° disponible en GitHub (github.com/CuchoLeo/Fuga) bajo licencia MIT, con documentaci√≥n detallada para facilitar reproducibilidad y extensi√≥n.</p>
<hr />
<h2 id="7-referencias">7. REFERENCIAS</h2>
<ol>
<li>
<p>Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. <em>arXiv preprint arXiv:1810.04805</em>.</p>
</li>
<li>
<p>Sanh, V., Debut, L., Chaumond, J., &amp; Wolf, T. (2019). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. <em>arXiv preprint arXiv:1910.01108</em>.</p>
</li>
<li>
<p>Huang, X., Khetan, A., Cvitkovic, M., &amp; Karnin, Z. (2020). TabTransformer: Tabular Data Modeling Using Contextual Embeddings. <em>arXiv preprint arXiv:2012.06678</em>.</p>
</li>
<li>
<p>Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). Attention is all you need. <em>Advances in neural information processing systems</em>, 30.</p>
</li>
<li>
<p>Lundberg, S. M., &amp; Lee, S. I. (2017). A unified approach to interpreting model predictions. <em>Advances in neural information processing systems</em>, 30.</p>
</li>
<li>
<p>Zhao, Y., Li, B., Li, X., Liu, W., &amp; Ren, S. (2019). Customer Churn Prediction Using Improved One-Class Support Vector Machines. <em>Advanced Data Mining and Applications: 11th International Conference</em>.</p>
</li>
<li>
<p>Kumar, A., &amp; Ravi, V. (2020). Customer churn prediction in telecom using machine learning in big data platform. <em>Journal of Big Data</em>, 7(1), 1-18.</p>
</li>
</ol>
<hr />
<p><strong>NOTA:</strong> Este trabajo fue desarrollado de manera individual como proyecto final del curso T√≥picos Avanzados en Inteligencia Artificial 2. Se utilizaron herramientas de asistencia de IA durante el proceso de desarrollo y documentaci√≥n, principalmente para generaci√≥n de c√≥digo boilerplate y estructuraci√≥n de documentos.</p>
<h2 id="8-recomendaciones-y-trabajo-futuro">8. RECOMENDACIONES Y TRABAJO FUTURO</h2>
<h3 id="81-mejoras-inmediatas-para-produccion">8.1 Mejoras Inmediatas para Producci√≥n</h3>
<p>Si este sistema fuera a desplegarse en un entorno de producci√≥n real, hay varias mejoras que implementar√≠a en los pr√≥ximos 3-6 meses.</p>
<p>Lo primero ser√≠a ajustar el threshold de decisi√≥n. Actualmente est√° en 0.5 (default), pero el an√°lisis de costos sugiere que 0.4 ser√≠a m√°s √≥ptimo. Esto aumentar√≠a el recall del 65% al 73%, detectando 33 churners adicionales por cada 2,000 clientes a cambio de solo 50 falsos positivos m√°s. El trade-off es claramente favorable.</p>
<p>Tambi√©n integrar√≠a el sistema con el CRM existente. Durante el desarrollo, la API est√° dise√±ada para esto, pero necesitar√≠a trabajar con el equipo de IT para mapear correctamente los campos y manejar la autenticaci√≥n. La idea ser√≠a que cada ma√±ana el equipo de retenci√≥n reciba autom√°ticamente una lista priorizada de clientes a contactar.</p>
<p>Un tercer aspecto cr√≠tico es el reentrenamiento. Los patrones de churn cambian con el tiempo. Recomendar√≠a reentrenar mensualmente con los √∫ltimos 12 meses de datos, manteniendo un registro de m√©tricas de drift para detectar cuando el modelo comienza a degradarse.</p>
<h3 id="82-extensiones-a-mediano-plazo">8.2 Extensiones a Mediano Plazo</h3>
<p>Hay varias extensiones que mejorar√≠an significativamente el sistema pero requieren m√°s esfuerzo de desarrollo.</p>
<p><strong>Features temporales</strong>: Actualmente el modelo ve un snapshot est√°tico del cliente. Agregar tendencias (c√≥mo ha evolucionado el balance, frecuencia de login, etc.) probablemente aumentar√≠a el ROC-AUC a 0.87-0.90. La implementaci√≥n requerir√≠a datos hist√≥ricos que no tengo actualmente.</p>
<p><strong>Predicci√≥n multi-horizonte</strong>: En lugar de predecir solo si el cliente har√° churn, predecir la probabilidad a 30, 60 y 90 d√≠as. Esto permitir√≠a estrategias de retenci√≥n diferenciadas (contacto urgente vs. engagement gradual).</p>
<p><strong>Sistema de recomendaciones</strong>: El modelo actual dice QU√â clientes est√°n en riesgo, pero no QU√â hacer. Un sistema que sugiera acciones espec√≠ficas ("Ofrecer tarjeta gold reduce churn en 23% para este perfil") ser√≠a mucho m√°s valioso. Requerir√≠a datos hist√≥ricos de intervenciones y sus resultados.</p>
<h3 id="83-investigacion-futura">8.3 Investigaci√≥n Futura</h3>
<p>Desde una perspectiva acad√©mica, hay varias preguntas interesantes que podr√≠an explorarse:</p>
<p>¬øPuede un modelo multimodal que combine datos tabulares, texto de interacciones con soporte, y an√°lisis de sentimiento mejorar las predicciones? Mi hip√≥tesis es que s√≠, especialmente si se captura frustraci√≥n del cliente en tickets de soporte, pero la implementaci√≥n ser√≠a compleja.</p>
<p>¬øGraph Neural Networks capturan mejor las relaciones entre clientes? Si asumimos que clientes similares tienden a tener comportamientos similares, representar la base de clientes como un grafo podr√≠a revelar patrones que modelos tradicionales pierden.</p>
<p>Por √∫ltimo, ¬øReinforcement Learning para optimizaci√≥n de estrategias de retenci√≥n? En lugar de predecir churn pasivamente, un agente que aprenda qu√© acciones maximizan retenci√≥n considerando restricciones de presupuesto ser√≠a el siguiente nivel.</p>
<hr />
<h2 id="9-lecciones-aprendidas">9. LECCIONES APRENDIDAS</h2>
<h3 id="91-tecnicas">9.1 T√©cnicas</h3>
<p>Algunas lecciones t√©cnicas que me llev√© de este proyecto:</p>
<p>El preprocesamiento importa MUCHO m√°s de lo que esperaba. Inicialmente asum√≠ que DistilBERT manejar√≠a autom√°ticamente variaciones en escala de features, pero sin normalizaci√≥n el modelo simplemente no converg√≠a. Este tipo de detalles no aparecen en papers pero son cr√≠ticos en la pr√°ctica.</p>
<p>Los class weights son una herramienta poderosa pero requieren tuning cuidadoso. Intent√© ratios de 2:1, 3:1, 4:1 y 5:1. El √≥ptimo (3.9:1) da un balance razonable, pero 5:1 generaba demasiados falsos positivos.</p>
<p>Un √©poca de entrenamiento es suficiente para datasets peque√±os. Esta fue contra-intuitiva - en deep learning normalmente se entrena por 10-100 √©pocas. Pero con solo 8K ejemplos de entrenamiento, el modelo memorizaba despu√©s de la primera √©poca.</p>
<h3 id="92-ingenieria-de-software">9.2 Ingenier√≠a de Software</h3>
<p>M√°s all√° de machine learning, aprend√≠ mucho sobre desarrollo de sistemas de software:</p>
<p>La documentaci√≥n debe escribirse simult√°neamente con el c√≥digo, no despu√©s. Intent√© dejarla para el final y me di cuenta de que hab√≠a olvidado por qu√© tom√© ciertas decisiones. Documentar mientras desarrollo fue mucho m√°s efectivo.</p>
<p>Docker es complicado pero vale la pena. Me tom√≥ 2 d√≠as resolver problemas de permisos y timeouts al descargar el LLM dentro del container, pero una vez funcionando, el deployment se volvi√≥ trivial.</p>
<p>FastAPI es excepcional. La validaci√≥n autom√°tica de tipos me salv√≥ de muchos bugs, y la documentaci√≥n con Swagger es tan buena que no necesit√© escribir documentaci√≥n adicional de la API.</p>
<h3 id="93-producto-y-negocio">9.3 Producto y Negocio</h3>
<p>Quiz√°s lo m√°s valioso fueron lecciones sobre c√≥mo desarrollar productos de ML que realmente se usen:</p>
<p>La interfaz conversacional fue la mejor decisi√≥n del proyecto. Inicialmente pens√© en solo proveer una API REST, pero agregar el chat hizo el sistema accesible para no-t√©cnicos. La diferencia entre "haz un POST a /predict con estos campos JSON" y "escribe tu pregunta en espa√±ol" es enorme.</p>
<p>El ROI debe ser claro desde el inicio. Pas√© tiempo calculando costos y beneficios no porque sea cr√≠tico para el informe acad√©mico, sino porque en una implementaci√≥n real, si no puedes justificar el ROI, el proyecto no se aprueba.</p>
<p>Los falsos negativos son m√°s costosos que los falsos positivos en este dominio. Esta es una decisi√≥n de negocio, no t√©cnica. En otros contextos (e.g., detecci√≥n de spam), podr√≠a ser al rev√©s.</p>
<hr />
<h2 id="10-anexos">10. ANEXOS</h2>
<h3 id="101-especificaciones-tecnicas">10.1 Especificaciones T√©cnicas</h3>
<p><strong>Hardware utilizado para desarrollo:</strong>
- MacBook Air M1, 8GB RAM
- Sin GPU (todo en CPU)
- Almacenamiento: ~5GB para modelos y datos</p>
<p><strong>Software y versiones:</strong>
- Python 3.10
- PyTorch 2.0.1
- Transformers 4.57.1
- FastAPI 0.104.0
- Scikit-learn 1.3.0</p>
<p><strong>Tiempos de ejecuci√≥n:</strong>
- Entrenamiento completo: ~5 minutos
- Inferencia (batch de 32): ~1.8 segundos
- Cold start de la API: ~15 segundos (carga de LLM)
- Query al agente conversacional: ~1.5 segundos</p>
<h3 id="102-estructura-del-repositorio">10.2 Estructura del Repositorio</h3>
<div class="codehilite"><pre><span></span><code>Fuga/
‚îú‚îÄ‚îÄ train_churn_prediction.py      # Entrenamiento del modelo (427 l√≠neas)
‚îú‚îÄ‚îÄ churn_chat_api.py               # API REST + LLM (565 l√≠neas)
‚îú‚îÄ‚îÄ run_local.py                    # Script de ejecuci√≥n (101 l√≠neas)
‚îú‚îÄ‚îÄ chat_interface.html             # Interfaz web
‚îú‚îÄ‚îÄ Churn_Modelling.csv            # Dataset (no incluido en Git)
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias
‚îú‚îÄ‚îÄ Dockerfile                      # Container Docker
‚îú‚îÄ‚îÄ docker-compose.yml             # Orquestaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Suite de evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py             # Tests exhaustivos (572 l√≠neas)
‚îÇ   ‚îú‚îÄ‚îÄ generate_report.py         # Generador de reportes
‚îÇ   ‚îî‚îÄ‚îÄ run_tests.sh               # Automatizaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ churn_model/                    # Modelo entrenado
‚îÇ   ‚îú‚îÄ‚îÄ model.safetensors          # Pesos (268 MB)
‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer files
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing_artifacts.pkl
‚îÇ
‚îî‚îÄ‚îÄ Documentaci√≥n/
    ‚îú‚îÄ‚îÄ DOCUMENTACION_CODIGO.md    # Explicaci√≥n l√≠nea por l√≠nea
    ‚îú‚îÄ‚îÄ DOCUMENTACION_MODELOS.md   # Decisiones t√©cnicas
    ‚îú‚îÄ‚îÄ DESPLIEGUE_GCP.md          # Gu√≠a cloud
    ‚îî‚îÄ‚îÄ README.md                   # Documentaci√≥n principal
</code></pre></div>

<h3 id="103-comandos-de-ejecucion">10.3 Comandos de Ejecuci√≥n</h3>
<p><strong>Entrenamiento:</strong></p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>train_churn_prediction.py
<span class="c1"># Output: churn_model/ con todos los artefactos</span>
</code></pre></div>

<p><strong>Ejecuci√≥n local:</strong></p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>run_local.py
<span class="c1"># Servidor en http://localhost:8000</span>
</code></pre></div>

<p><strong>Tests:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>tests
./run_tests.sh
<span class="c1"># Genera test_results/ con visualizaciones y m√©tricas</span>
</code></pre></div>

<p><strong>Docker:</strong></p>
<div class="codehilite"><pre><span></span><code>docker-compose<span class="w"> </span>up<span class="w"> </span>--build
<span class="c1"># Servidor en http://localhost:8000</span>
</code></pre></div>

<h3 id="104-ejemplos-de-uso-de-la-api">10.4 Ejemplos de Uso de la API</h3>
<p><strong>Predicci√≥n individual:</strong></p>
<div class="codehilite"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/predict<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;CreditScore&quot;: 650,</span>
<span class="s1">    &quot;Geography&quot;: &quot;France&quot;,</span>
<span class="s1">    &quot;Gender&quot;: &quot;Male&quot;,</span>
<span class="s1">    &quot;Age&quot;: 42,</span>
<span class="s1">    &quot;Tenure&quot;: 5,</span>
<span class="s1">    &quot;Balance&quot;: 125000,</span>
<span class="s1">    &quot;NumOfProducts&quot;: 2,</span>
<span class="s1">    &quot;HasCrCard&quot;: 1,</span>
<span class="s1">    &quot;IsActiveMember&quot;: 0,</span>
<span class="s1">    &quot;EstimatedSalary&quot;: 95000</span>
<span class="s1">  }&#39;</span>

<span class="c1"># Response:</span>
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;churn_probability&quot;</span>:<span class="w"> </span><span class="m">0</span>.73,
<span class="w">  </span><span class="s2">&quot;prediction&quot;</span>:<span class="w"> </span><span class="s2">&quot;CHURN&quot;</span>,
<span class="w">  </span><span class="s2">&quot;confidence&quot;</span>:<span class="w"> </span><span class="s2">&quot;HIGH&quot;</span>
<span class="o">}</span>
</code></pre></div>

<p><strong>Chat conversacional:</strong></p>
<div class="codehilite"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/chat<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;message&quot;: &quot;Mu√©strame los 5 clientes con mayor riesgo&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>

<h3 id="105-resultados-completos-de-evaluacion">10.5 Resultados Completos de Evaluaci√≥n</h3>
<p>Todos los resultados est√°n disponibles en <code>test_results/</code>:
- <code>informe_completo.html</code>: Reporte interactivo con todas las visualizaciones
- <code>metrics.json</code>: M√©tricas en formato estructurado
- <code>confusion_matrix.png</code>: Visualizaci√≥n de la matriz de confusi√≥n
- <code>roc_curve.png</code>: Curva ROC
- <code>precision_recall_curve.png</code>: Curva PR
- <code>threshold_analysis.json</code>: Performance a diferentes umbrales</p>
<hr />
<h2 id="11-impacto-y-aplicabilidad">11. IMPACTO Y APLICABILIDAD</h2>
<h3 id="111-transferibilidad-a-otros-dominios">11.1 Transferibilidad a Otros Dominios</h3>
<p>Aunque este trabajo se enfoca en churn bancario, la arquitectura es aplicable a otros problemas similares:</p>
<p><strong>Telecomunicaciones:</strong> El churn en telcos tiene patrones similares. Solo requerir√≠a reentrenar con features espec√≠ficas del dominio (minutos consumidos, datos, llamadas al soporte).</p>
<p><strong>SaaS y Suscripciones:</strong> Empresas como Netflix o Spotify enfrentan el mismo problema. Las features ser√≠an diferentes (tiempo de uso, contenido consumido), pero la arquitectura se mantiene.</p>
<p><strong>Retail:</strong> Predecir clientes que dejar√°n de comprar. Requerir√≠a features transaccionales (recencia, frecuencia, valor monetario - modelo RFM).</p>
<p>La clave es que la metodolog√≠a (Transformer para clasificaci√≥n + LLM para interpretaci√≥n) es agn√≥stica al dominio espec√≠fico.</p>
<h3 id="112-contribucion-a-la-democratizacion-de-ia">11.2 Contribuci√≥n a la Democratizaci√≥n de IA</h3>
<p>Un aspecto que me parece importante destacar es c√≥mo este proyecto contribuye a hacer IA m√°s accesible:</p>
<p><strong>C√≥digo completamente open-source:</strong> Todo est√° en GitHub bajo licencia MIT. Cualquier organizaci√≥n puede usarlo sin costo.</p>
<p><strong>Documentaci√≥n exhaustiva:</strong> ~20,000 palabras de documentaci√≥n. No solo explico QU√â hace el c√≥digo, sino POR QU√â tom√© cada decisi√≥n.</p>
<p><strong>Opciones de deployment flexibles:</strong> Local (para testing), Docker (para consistencia), Cloud (para producci√≥n). No todos tienen los mismos recursos.</p>
<p><strong>Sin requerimientos de GPU:</strong> El sistema completo corre en una laptop est√°ndar. Esto es cr√≠tico para organizaciones peque√±as.</p>
<h3 id="113-consideraciones-eticas">11.3 Consideraciones √âticas</h3>
<p>Finalmente, es importante considerar implicaciones √©ticas de sistemas como este:</p>
<p><strong>Sesgo algor√≠tmico:</strong> El modelo podr√≠a perpetuar sesgos presentes en datos hist√≥ricos. Por ejemplo, si hist√≥ricamente ciertos grupos demogr√°ficos recibieron peor servicio y por eso tienen mayor churn, el modelo podr√≠a penalizar a esos grupos. Revis√© las tasas de churn por g√©nero y geograf√≠a y no encontr√© sesgos evidentes, pero un an√°lisis m√°s profundo ser√≠a apropiado.</p>
<p><strong>Privacidad:</strong> El sistema procesa datos sensibles de clientes. En una implementaci√≥n real, debe cumplir con regulaciones como GDPR. La arquitectura permite deployment on-premise, lo cual ayuda a mantener datos bajo control de la organizaci√≥n.</p>
<p><strong>Transparencia:</strong> Los clientes tienen derecho a saber si est√°n siendo evaluados por un algoritmo. Las organizaciones que implementen esto deber√≠an ser transparentes sobre su uso.</p>
<p><strong>Automatizaci√≥n vs. Asistencia:</strong> El sistema est√° dise√±ado para asistir decisiones humanas, no reemplazarlas. Las predicciones deben ser revisadas por expertos antes de tomar acciones.</p>
<hr />
<h2 id="12-conclusion-final">12. CONCLUSI√ìN FINAL</h2>
<p>Este proyecto demuestra que es viable desarrollar sistemas de predicci√≥n de churn que combinen performance t√©cnica s√≥lida con accesibilidad pr√°ctica. El modelo alcanz√≥ un ROC-AUC de 0.841, comparable con resultados publicados en conferencias acad√©micas, mientras que el an√°lisis de ROI indica viabilidad econ√≥mica clara con retorno del 113% en el primer a√±o.</p>
<p>M√°s all√° de las m√©tricas, lo que considero m√°s valioso es haber abordado el problema de manera integral. No solo entren√© un modelo, sino que constru√≠ un sistema completo que puede desplegarse, mantenerse y usarse en condiciones reales. Esta perspectiva end-to-end es cr√≠tica para que proyectos de ML generen valor real.</p>
<p>Las lecciones aprendidas durante el desarrollo ser√°n aplicables a futuros proyectos. En particular, la importancia del preprocesamiento cuidadoso, el dise√±o de interfaces accesibles, y la consideraci√≥n de trade-offs de negocio desde las etapas tempranas del desarrollo.</p>
<p>Si tuviera que resumir una lecci√≥n central: los modelos de ML son solo una pieza del sistema. El deployment, la documentaci√≥n, la interfaz de usuario, y la integraci√≥n con procesos de negocio existentes son igualmente importantes para el √©xito del proyecto.</p>
<p>El c√≥digo est√° disponible p√∫blicamente en GitHub (github.com/CuchoLeo/Fuga) con documentaci√≥n exhaustiva. Espero que sirva como referencia √∫til para otros estudiantes e investigadores trabajando en problemas similares.</p>
<hr />
<p><strong>Agradecimientos:</strong> Agradezco la asesor√≠a del profesor [nombre] y los comentarios de compa√±eros durante el desarrollo de este trabajo. Tambi√©n reconozco el uso de herramientas de asistencia de IA (Claude Code de Anthropic) para generaci√≥n de c√≥digo boilerplate, estructuraci√≥n de documentos, y debugging. El dise√±o, implementaci√≥n, evaluaci√≥n y an√°lisis representan trabajo original del autor.</p>
<hr />
<p><strong>Fecha de finalizaci√≥n:</strong> Noviembre 2025<br />
<strong>Palabras:</strong> ~6,500<br />
<strong>C√≥digo:</strong> ~2,800 l√≠neas Python<br />
<strong>Documentaci√≥n:</strong> ~20,000 palabras totales  </p>
<hr />
<p><em>"The best model is the one that actually gets used."</em> - An√≥nimo</p>

    <div class="footer">
        <hr>
        <p><strong>Sistema de Predicci√≥n de Churn - Proyecto Final</strong></p>
        <p>Generado autom√°ticamente el 02 de November de 2025 a las 16:14:05</p>
        <p>ü§ñ <em>Desarrollado con Claude Code</em></p>
    </div>

    <script>
        // Auto-generar tabla de contenidos
        document.addEventListener('DOMContentLoaded', function() {
            console.log('Informe cargado correctamente');
        });
    </script>
</body>
</html>
