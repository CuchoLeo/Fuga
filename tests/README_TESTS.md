# üß™ Sistema de Pruebas Completas - Modelo de Predicci√≥n de Churn

Este conjunto de herramientas permite evaluar exhaustivamente el modelo de predicci√≥n de churn y generar reportes profesionales para el informe final.

---

## üìã Contenido

1. [Archivos Incluidos](#archivos-incluidos)
2. [Requisitos](#requisitos)
3. [Instalaci√≥n](#instalaci√≥n)
4. [Uso R√°pido](#uso-r√°pido)
5. [Resultados Generados](#resultados-generados)
6. [Interpretaci√≥n de M√©tricas](#interpretaci√≥n-de-m√©tricas)
7. [Personalizaci√≥n](#personalizaci√≥n)

---

## üìÅ Archivos Incluidos

```
Fuga/
‚îú‚îÄ‚îÄ test_models.py          # Script principal de evaluaci√≥n
‚îú‚îÄ‚îÄ generate_report.py      # Generador de reporte HTML
‚îú‚îÄ‚îÄ run_tests.sh           # Script de ejecuci√≥n automatizada
‚îî‚îÄ‚îÄ README_TESTS.md        # Esta documentaci√≥n
```

### `test_models.py`
Script principal que:
- Carga el modelo entrenado
- Genera predicciones en datos de test
- Calcula m√©tricas exhaustivas
- Crea visualizaciones profesionales
- Analiza rendimiento por segmentos
- Guarda todos los resultados en JSON

### `generate_report.py`
Generador de reporte HTML que:
- Lee los resultados de `test_models.py`
- Crea un reporte HTML interactivo
- Embebe todas las visualizaciones
- Incluye recomendaciones autom√°ticas
- Formato profesional listo para presentar

### `run_tests.sh`
Script bash que ejecuta todo el pipeline:
- Verifica requisitos
- Ejecuta las pruebas
- Genera el reporte
- Muestra resumen de resultados

---

## ‚öôÔ∏è Requisitos

### Python 3.10+
```bash
python3 --version  # Debe ser >= 3.10
```

### Dependencias
Todas est√°n en `requirements.txt`:
- transformers
- torch
- scikit-learn
- pandas
- numpy
- matplotlib
- seaborn

### Modelo Entrenado
Debe existir el directorio `churn_model/` con el modelo entrenado.

Si no existe:
```bash
python3 train_churn_prediction.py
```

---

## üöÄ Instalaci√≥n

```bash
# 1. Clonar o navegar al directorio
cd Fuga/

# 2. Activar entorno virtual (recomendado)
python3 -m venv venv
source venv/bin/activate  # Mac/Linux
# O: venv\Scripts\activate  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt
```

---

## ‚ö° Uso R√°pido

### Opci√≥n 1: Script Automatizado (Recomendado)

```bash
# Ejecutar todo el pipeline
chmod +x run_tests.sh
./run_tests.sh
```

Esto:
1. ‚úÖ Verifica requisitos
2. ‚úÖ Entrena modelo si no existe
3. ‚úÖ Ejecuta todas las pruebas
4. ‚úÖ Genera reporte HTML
5. ‚úÖ Muestra resumen

### Opci√≥n 2: Manual (Paso a Paso)

```bash
# 1. Ejecutar pruebas
python3 test_models.py

# 2. Generar reporte HTML
python3 generate_report.py

# 3. Abrir reporte
open test_results/informe_completo.html  # macOS
```

---

## üìä Resultados Generados

Todos los resultados se guardan en `test_results/`:

```
test_results/
‚îú‚îÄ‚îÄ informe_completo.html           # üåü Reporte principal (abrir en navegador)
‚îú‚îÄ‚îÄ metrics.json                    # M√©tricas en formato JSON
‚îú‚îÄ‚îÄ classification_report.json      # Reporte detallado de clasificaci√≥n
‚îú‚îÄ‚îÄ test_summary.json              # Resumen ejecutivo
‚îú‚îÄ‚îÄ threshold_analysis.json        # An√°lisis de umbrales
‚îú‚îÄ‚îÄ segments_analysis.json         # An√°lisis por segmentos
‚îú‚îÄ‚îÄ error_examples.csv             # Ejemplos de errores
‚îú‚îÄ‚îÄ confusion_matrix.png           # Matriz de confusi√≥n
‚îú‚îÄ‚îÄ roc_curve.png                  # Curva ROC
‚îú‚îÄ‚îÄ precision_recall_curve.png     # Curva Precision-Recall
‚îú‚îÄ‚îÄ probability_distribution.png   # Distribuci√≥n de probabilidades
‚îú‚îÄ‚îÄ metrics_summary.png            # Resumen visual de m√©tricas
‚îî‚îÄ‚îÄ threshold_analysis.png         # Visualizaci√≥n de umbrales
```

### üåü Archivo Principal

**`informe_completo.html`** - Reporte HTML interactivo con:
- ‚úÖ Resumen ejecutivo con m√©tricas clave
- ‚úÖ Matriz de confusi√≥n interactiva
- ‚úÖ Curvas ROC y Precision-Recall
- ‚úÖ An√°lisis de umbrales
- ‚úÖ Recomendaciones autom√°ticas
- ‚úÖ Conclusiones y pr√≥ximos pasos
- ‚úÖ Dise√±o profesional responsive

---

## üìà Interpretaci√≥n de M√©tricas

### M√©tricas Principales

| M√©trica | Descripci√≥n | Valor Ideal |
|---------|-------------|-------------|
| **Accuracy** | % de predicciones correctas (total) | > 0.80 |
| **Precision** | De los que predecimos CHURN, % correctos | > 0.70 |
| **Recall** | De los que hacen CHURN, % detectados | > 0.70 |
| **F1-Score** | Balance entre Precision y Recall | > 0.70 |
| **ROC-AUC** | Capacidad de discriminaci√≥n | > 0.80 |

### Matriz de Confusi√≥n

```
                    Predicci√≥n
                 No Churn  |  Churn
Real ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
No Churn ‚îÇ   TN (‚úÖ)   ‚îÇ   FP (‚ùå)
         ‚îÇ  Correcto   ‚îÇ   Error
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Churn    ‚îÇ   FN (‚ùå)   ‚îÇ   TP (‚úÖ)
         ‚îÇ   Error     ‚îÇ  Correcto
```

- **TN (True Negative)**: Cliente no hizo churn y lo predijimos correctamente ‚úÖ
- **FP (False Positive)**: Cliente no hizo churn pero predijimos que s√≠ ‚ùå (Costo: campa√±a innecesaria)
- **FN (False Negative)**: Cliente hizo churn pero no lo detectamos ‚ùå (Costo: cliente perdido)
- **TP (True Positive)**: Cliente hizo churn y lo detectamos ‚úÖ (√âxito: oportunidad de retenci√≥n)

### Trade-offs

**Aumentar Recall (detectar m√°s churners):**
- ‚úÖ Capturamos m√°s clientes en riesgo
- ‚ùå M√°s falsos positivos (campa√±as innecesarias)
- üí° Usar si: El costo de perder un cliente > costo de campa√±a

**Aumentar Precision (evitar falsos positivos):**
- ‚úÖ Menos campa√±as innecesarias
- ‚ùå Perdemos algunos clientes en riesgo
- üí° Usar si: El costo de campa√±a es alto

---

## üéØ Personalizaci√≥n

### Cambiar Umbral de Decisi√≥n

Edita `test_models.py` l√≠nea ~365:

```python
# Cambiar umbrales a probar
thresholds_to_test = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
```

### Agregar M√°s Visualizaciones

Agrega en `test_models.py` despu√©s de la l√≠nea 300:

```python
# Tu c√≥digo de visualizaci√≥n
fig, ax = plt.subplots(figsize=(10, 6))
# ... tu gr√°fico
plt.savefig(RESULTS_DIR / 'mi_grafico.png', dpi=300)
```

Luego actualiza `generate_report.py` para incluirlo en el HTML.

### Personalizar Reporte HTML

Edita `generate_report.py`:
- **Colores**: Modifica la secci√≥n `<style>` (l√≠nea ~80)
- **Secciones**: Agrega nuevas secciones HTML (despu√©s l√≠nea ~400)
- **Logo**: Agrega tu logo en base64

---

## üìù Ejemplos de Uso

### Evaluaci√≥n Completa

```bash
# Ejecutar todo
./run_tests.sh

# Ver reporte
open test_results/informe_completo.html
```

### Solo M√©tricas (Sin Reporte)

```bash
python3 test_models.py
cat test_results/metrics.json
```

### Solo Reporte (Actualizar Dise√±o)

```bash
# Editar generate_report.py
# Luego regenerar
python3 generate_report.py
```

### Exportar M√©tricas

```bash
# M√©tricas en JSON
cat test_results/metrics.json | jq '.'

# Ejemplos de errores en CSV
open test_results/error_examples.csv
```

---

## üêõ Soluci√≥n de Problemas

### Error: "No se encontr√≥ el modelo"

```bash
# Soluci√≥n: Entrenar modelo primero
python3 train_churn_prediction.py
```

### Error: "ModuleNotFoundError"

```bash
# Soluci√≥n: Instalar dependencias
pip install -r requirements.txt
```

### Reporte HTML no se ve bien

```bash
# Soluci√≥n: Usar navegador moderno (Chrome, Firefox, Safari)
# Evitar Internet Explorer
```

### Im√°genes no aparecen en el reporte

```bash
# Verificar que existen
ls test_results/*.png

# Si faltan, regenerar
python3 test_models.py
```

---

## üí° Tips Profesionales

### Para el Informe Final

1. **Captura de pantalla**: Usa las visualizaciones PNG para slides
2. **M√©tricas JSON**: Importa a Excel/LaTeX para tablas
3. **Reporte HTML**: Comparte link o PDF del navegador
4. **An√°lisis de errores**: Usa `error_examples.csv` para casos espec√≠ficos

### Formato PDF

```bash
# Desde el navegador:
# 1. Abrir informe_completo.html
# 2. Ctrl+P / Cmd+P
# 3. "Guardar como PDF"
# 4. Configurar m√°rgenes a "Ninguno"
```

### Automatizaci√≥n

```bash
# Agregar a cron para evaluaci√≥n peri√≥dica
0 0 * * * cd /path/to/Fuga && ./run_tests.sh
```

---

## üìö Referencias

- [Documentaci√≥n scikit-learn - Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [ROC Curve Explained](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)
- [Precision vs Recall](https://en.wikipedia.org/wiki/Precision_and_recall)

---

## ü§ù Soporte

Si tienes problemas:

1. Verifica requisitos (Python 3.10+, dependencias)
2. Revisa logs de error
3. Consulta secci√≥n "Soluci√≥n de Problemas"
4. Verifica que `churn_model/` existe

---

## ‚úÖ Checklist para Informe Final

- [ ] Ejecutar `./run_tests.sh`
- [ ] Revisar `test_results/informe_completo.html`
- [ ] Exportar reporte a PDF
- [ ] Incluir visualizaciones PNG en slides
- [ ] Copiar m√©tricas JSON a documentaci√≥n
- [ ] Analizar ejemplos de errores
- [ ] Documentar interpretaci√≥n de resultados
- [ ] Incluir recomendaciones del reporte

---

**¬°Listo para generar tu informe profesional! üöÄ**

Para cualquier duda, consulta la documentaci√≥n o revisa los comentarios en `test_models.py` y `generate_report.py`.
