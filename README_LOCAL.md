# ğŸš€ Ejecutar Churnito Localmente (Sin Docker)

Esta guÃ­a te permite ejecutar Churnito directamente en tu mÃ¡quina sin necesidad de Docker.

---

## ğŸ“‹ **REQUISITOS PREVIOS**

### 1. Python 3.11 o superior
```bash
# Verificar versiÃ³n de Python
python3 --version
# Debe mostrar: Python 3.11.x o superior
```

### 2. pip (gestor de paquetes Python)
```bash
# Verificar pip
pip3 --version
```

---

## âš¡ **INICIO RÃPIDO (3 pasos)**

### **Paso 1: Instalar dependencias**
```bash
# Crear entorno virtual (recomendado)
python3 -m venv venv

# Activar entorno virtual
# En Mac/Linux:
source venv/bin/activate
# En Windows:
venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### **Paso 2: Ejecutar el servidor**
```bash
python run_local.py
```

### **Paso 3: Abrir en navegador**
```
http://localhost:8000
```

---

## ğŸ“¦ **INSTALACIÃ“N DETALLADA**

### **OpciÃ³n A: Usando el script automÃ¡tico (Recomendado)**

```bash
# 1. Navegar al directorio del proyecto
cd Fuga/

# 2. Crear entorno virtual
python3 -m venv venv

# 3. Activar entorno virtual
source venv/bin/activate  # Mac/Linux
# O en Windows: venv\Scripts\activate

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Ejecutar servidor
python run_local.py
```

**El script verificarÃ¡ automÃ¡ticamente:**
- âœ… Archivos necesarios
- âœ… Dependencias instaladas
- âœ… CreaciÃ³n de directorios

---

### **OpciÃ³n B: Usando uvicorn directamente**

```bash
# 1. Activar entorno virtual (si usas uno)
source venv/bin/activate

# 2. Ejecutar servidor con uvicorn
uvicorn churn_chat_api:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸŒ **ACCEDER A LA APLICACIÃ“N**

Una vez iniciado el servidor, abre tu navegador:

| URL | DescripciÃ³n |
|-----|-------------|
| `http://localhost:8000` | ğŸ’¬ Interfaz de chat con Churnito |
| `http://localhost:8000/docs` | ğŸ“– DocumentaciÃ³n interactiva (Swagger) |
| `http://localhost:8000/health` | â¤ï¸ Estado del sistema |
| `http://localhost:8000/api` | ğŸ“Š InformaciÃ³n de endpoints |

---

## ğŸ§ª **PRIMERA PRUEBA**

1. Abre `http://localhost:8000` en tu navegador
2. DeberÃ­as ver la interfaz de chat con tema oscuro
3. Escribe: **"Hola Churnito, Â¿cÃ³mo te llamas?"**
4. Churnito deberÃ­a responder presentÃ¡ndose

**Otras consultas de prueba:**
```
MuÃ©strame los 10 clientes con mayor riesgo de fuga
Â¿CuÃ¡l es la tasa de churn actual?
Â¿CuÃ¡ntos clientes de alto valor tenemos?
Dame estrategias para reducir el churn
```

---

## ğŸ“‚ **ESTRUCTURA DE ARCHIVOS**

```
Fuga/
â”œâ”€â”€ run_local.py              â† Script para ejecutar localmente
â”œâ”€â”€ churn_chat_api.py         â† AplicaciÃ³n principal (FastAPI)
â”œâ”€â”€ chat_interface.html       â† Interfaz web del chat
â”œâ”€â”€ train_churn_prediction.py â† Entrenamiento del modelo
â”œâ”€â”€ Churn_Modelling.csv       â† Datos de entrenamiento
â”œâ”€â”€ requirements.txt          â† Dependencias Python
â”œâ”€â”€ churn_model/              â† Modelo entrenado (se crea automÃ¡ticamente)
â””â”€â”€ trained_model/            â† LLM descargado (se crea automÃ¡ticamente)
```

---

## âš™ï¸ **CONFIGURACIÃ“N AVANZADA**

### **Cambiar puerto:**
```bash
# Editar run_local.py, lÃ­nea ~77:
uvicorn.run(
    "churn_chat_api:app",
    host="0.0.0.0",
    port=8080,  # â† Cambiar aquÃ­
    reload=True
)
```

### **Desactivar auto-reload:**
```bash
# Para producciÃ³n, cambia reload=True a reload=False
uvicorn.run(
    "churn_chat_api:app",
    host="0.0.0.0",
    port=8000,
    reload=False  # â† Cambiar aquÃ­
)
```

---

## ğŸ›‘ **DETENER EL SERVIDOR**

Presiona `Ctrl+C` en la terminal donde estÃ¡ corriendo el servidor.

```bash
# Salida esperada:
^C
======================================================================
ğŸ‘‹ Servidor detenido
======================================================================
```

---

## ğŸ› **SOLUCIÃ“N DE PROBLEMAS**

### **Error: "No module named 'fastapi'"**
```bash
# SoluciÃ³n: Instalar dependencias
pip install -r requirements.txt
```

### **Error: "Address already in use"**
```bash
# El puerto 8000 ya estÃ¡ en uso por otro proceso
# SoluciÃ³n 1: Detener el otro proceso
lsof -ti:8000 | xargs kill -9

# SoluciÃ³n 2: Cambiar el puerto en run_local.py
```

### **Error: "churn_model not found"**
```bash
# SoluciÃ³n: Entrenar el modelo primero
python train_churn_prediction.py
```

### **LLM tarda mucho en cargar (primera vez)**
```
âœ… NORMAL - La primera vez descarga ~3GB del modelo Qwen2.5
â±ï¸ Tiempo estimado: 5-10 minutos (dependiendo de tu conexiÃ³n)
ğŸ’¾ Se guarda en ./trained_model/ para usos futuros
```

### **Error: "ModuleNotFoundError: No module named 'torch'"**
```bash
# Instalar PyTorch manualmente
pip install torch --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

---

## ğŸ†š **DOCKER vs LOCAL**

| Aspecto | Docker | Local |
|---------|--------|-------|
| **InstalaciÃ³n** | Solo Docker Desktop | Python + dependencias |
| **Aislamiento** | âœ… Completo | âŒ Usa Python del sistema |
| **Velocidad inicial** | Lenta (build imagen) | RÃ¡pida |
| **Desarrollo** | Reconstruir imagen | âœ… Auto-reload instantÃ¡neo |
| **Portabilidad** | âœ… Funciona igual en cualquier OS | Depende del entorno |
| **Uso recomendado** | ProducciÃ³n, distribuciÃ³n | Desarrollo, pruebas rÃ¡pidas |

---

## ğŸ“ **NOTAS IMPORTANTES**

1. **Entorno virtual recomendado**: Usa `venv` para evitar conflictos con otras instalaciones de Python
2. **Primera ejecuciÃ³n**: El LLM se descargarÃ¡ (~3GB), esto puede tardar varios minutos
3. **Modelo de churn**: Si no existe en `churn_model/`, debes ejecutar `train_churn_prediction.py` primero
4. **Memoria RAM**: El LLM requiere ~4-6GB de RAM disponible
5. **Auto-reload**: El modo desarrollo recarga automÃ¡ticamente cuando cambias el cÃ³digo

---

## ğŸ¯ **PRÃ“XIMOS PASOS**

Una vez que el servidor estÃ© corriendo:

1. âœ… Prueba la interfaz web en `http://localhost:8000`
2. âœ… Explora la documentaciÃ³n en `/docs`
3. âœ… Conversa con Churnito y prueba diferentes consultas
4. âœ… Revisa los logs en la terminal para debug

---

## ğŸ¤ **AYUDA**

Si tienes problemas:
1. Verifica que Python 3.11+ estÃ© instalado
2. AsegÃºrate de estar en el directorio correcto (`Fuga/`)
3. Revisa que todas las dependencias estÃ©n instaladas
4. Consulta la secciÃ³n de "SoluciÃ³n de problemas" arriba

---

**Â¡Disfruta conversando con Churnito! ğŸ¤–**
